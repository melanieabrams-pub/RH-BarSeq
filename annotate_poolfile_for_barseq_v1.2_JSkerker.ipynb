{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate poolfile after tnseq mapping with gene IDs from gff3 file\n",
    "# creates a file ready for barseq counting\n",
    "# fully annotated \n",
    "# removes the offending line that is super long - and causes problems in excel\n",
    "# version 1.2\n",
    "# sort pool by scaffold and position\n",
    "# September 1, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/MBP2019/annotate-piggyBAC/annotate_poolfile\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/MBP2019/annotate-piggyBAC/annotate_poolfile/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1373_Z1.fa\n",
      "D1373_Z1_fgenesh.gff3\n",
      "\u001b[34mannotate-poolFile-fgenesh\u001b[m\u001b[m/\n",
      "\u001b[34mannotation_files\u001b[m\u001b[m/\n",
      "\u001b[34mfgenesh-annotation\u001b[m\u001b[m/\n",
      "new_YS2_CBS432_CDS_only_nomito_nomicron.gff3\n",
      "piggyBAC_all20_poolfile_aug12_2020.txt\n",
      "piggyBAC_all20_poolfile_aug12_2020.txt_fgenesh_annotated_for_BarSeq_final.txt\n",
      "\u001b[34mversion1.0\u001b[m\u001b[m/\n",
      "\u001b[34mversion1.1.fullyAnnotated\u001b[m\u001b[m/\n",
      "\u001b[34mversion1.1.old\u001b[m\u001b[m/\n",
      "\u001b[34mversion1.2.carly_fullyAnnotated\u001b[m\u001b[m/\n",
      "\u001b[34mversion1.3.fgenesh_fullyAnnotated\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import operator\n",
    "from datetime import datetime\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 548129 barcodes from piggyBAC_all20_poolfile_aug12_2020.txt\n"
     ]
    }
   ],
   "source": [
    "# Load poolfile \n",
    "\n",
    "poolFileName = 'piggyBAC_all20_poolfile_aug12_2020.txt'\n",
    "\n",
    "try:\n",
    "    with open(poolFileName, 'rb') as poolFileHandle:\n",
    "        poolFrame = pd.read_csv(poolFileHandle,sep='\\t')\n",
    "        poolFileHandle.close()\n",
    "        poolFrame.dropna(how='all')\n",
    "        statusUpdate =  \"Read \"+ str(len(poolFrame)) + \" barcodes from \"+poolFileName\n",
    "        print(statusUpdate)\n",
    "except IOError:\n",
    "    statusUpdate =  \"Could not read file: \"+poolFileName\n",
    "    print(statusUpdate)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting pool entries by location.\n",
      "Sorted scaffolds by length: ['scchrIV', 'sp4', 'scchrXV', 'scchrVII', 'scchrXII', 'sp7', 'sp15', 'sp12', 'sp16', 'scchrXVI', 'scchrXIII', 'sp13', 'scchrII', 'sp2', 'scchrXIV', 'sp14', 'scchrX', 'sp10', 'sp11', 'scchrXI', 'sp5', 'scchrV', 'scchrVIII', 'sp8', 'scchrIX', 'sp9', 'scchrIII', 'sp3', 'sp6', 'scchrVI', 'scchrI', 'sp1', 'scchrMito']\n"
     ]
    }
   ],
   "source": [
    "# convert scaffolds to dictionary of SeqRecord objects\n",
    "\n",
    "genomeFiles = 'D1373_Z1.fa'\n",
    "scaffoldSequences = SeqIO.to_dict(SeqIO.parse(genomeFiles, \"fasta\"))\n",
    "\n",
    "\n",
    "print(\"Sorting pool entries by location.\")\n",
    "poolFrame.sort_values(['scaffold','pos'],ascending=[1,1],inplace=True)\n",
    "        \n",
    "# sort scaffolds by length\n",
    "\n",
    "scaffoldLengths = {}\n",
    "totalGenome = 0\n",
    "for scaffold in scaffoldSequences:\n",
    "        scaffoldLengths[scaffold] = len(scaffoldSequences[scaffold].seq)\n",
    "        totalGenome+=len(scaffoldSequences[scaffold].seq)\n",
    "\n",
    "sorted_scaffoldLengths = sorted(scaffoldLengths.items(), key=operator.itemgetter(1), reverse=True)\n",
    "scaffoldOrder = []\n",
    "for scaff in sorted_scaffoldLengths:\n",
    "    scaffoldOrder.append(scaff[0])\n",
    "    \n",
    "print(f'Sorted scaffolds by length: {scaffoldOrder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 51372 features from new_YS2_CBS432_CDS_only_nomito_nomicron.gff3\n"
     ]
    }
   ],
   "source": [
    "# Load gff file\n",
    "\n",
    "gffFileName = 'new_YS2_CBS432_CDS_only_nomito_nomicron.gff3'\n",
    "\n",
    "try:\n",
    "    with open(gffFileName, 'rb') as FileHandle: # why rb mode?\n",
    "        genestext = FileHandle.readlines()\n",
    "        FileHandle.close()\n",
    "        statusUpdate = \"Read \"+str(len(genestext))+\" features from \"+gffFileName\n",
    "        print(statusUpdate)\n",
    "except IOError:\n",
    "    statusUpdate = \"Could not read file: \"+gffFileName\n",
    "    print(statusUpdate)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing GFF for gene locations and attributes\n"
     ]
    }
   ],
   "source": [
    "# Parse GFF file for gene locations and attributes\n",
    "\n",
    "statusUpdate =  \"Parsing GFF for gene locations and attributes\"\n",
    "print(statusUpdate)\n",
    "\n",
    "\n",
    "\n",
    "# Build list of RNAs\n",
    "# parse GFF into OrderedDict called Genes\n",
    "\n",
    "Genes = collections.OrderedDict()\n",
    "Counter = 0\n",
    "for genesline in genestext:\n",
    "    genesfields = genesline.decode().split('\\t')\n",
    "    if len(genesfields) == 9:\n",
    "        scaffold,evidence,featureType,start,end,flag,strand,frame,comments = genesfields\n",
    "        #translate start/end to zero based indexing with non-inclusive end\n",
    "        start = int(start)-1\n",
    "        end = int(end)\n",
    "        if featureType == 'mRNA':\n",
    "            notes = dict((k.strip(), v.strip()) for k,v in (item.split('=') for item in comments.split(';')))\n",
    "                    \n",
    "            Genes[notes['ID']] = {'scaffold':scaffold,\n",
    "                                        'start':int(start),\n",
    "                                        'end':int(end),\n",
    "                                        'strand':strand,\n",
    "                                        'exon':[],\n",
    "                                        'intron':[],\n",
    "                                        'Parent':notes['Parent'],\n",
    "                                        }\n",
    "        elif featureType == 'CDS':\n",
    "            notes = dict((k.strip(), v.strip()) for k,v in (item.split('=') for item in comments.split(';')))\n",
    "            if len(Genes[notes['Parent']]['exon']) > 0:\n",
    "                Genes[notes['Parent']]['intron'].append([Genes[notes['Parent']]['exon'][-1][1]+1,start-1])\n",
    "            Genes[notes['Parent']]['exon'].append([start,end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaffold': 'scchrXIII',\n",
       " 'start': 460,\n",
       " 'end': 4684,\n",
       " 'strand': '-',\n",
       " 'exon': [[460, 3791], [3890, 4684]],\n",
       " 'intron': [[3792, 3889]],\n",
       " 'Parent': 'nbis-gene-4784'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example, has two exons and one intron\n",
    "Genes['nbisL2-cds-4605']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build list of locations in the genome and in genic and non-genic regions\n",
    "# should have intron / exon / intergenic ?   what happens to them?\n",
    "# and for fitness calculation - what happens to exon/intron/intergenic?\n",
    "# does it sort by nearest gene?\n",
    "\n",
    "\n",
    "\n",
    "locationTypes = {}\n",
    "nearestGeneDict = {}\n",
    "for scaffold in scaffoldOrder:\n",
    "    locationTypes[scaffold] = ['intergenic']*scaffoldLengths[scaffold]\n",
    "    nearestGeneDict[scaffold] = ['intergenic']*scaffoldLengths[scaffold]\n",
    "\n",
    "    \n",
    "for locationType in ['intron','exon']:\n",
    "    for Gene in Genes:\n",
    "        for entry in Genes[Gene][locationType]:\n",
    "            for position in range(entry[0],entry[1]):\n",
    "                locationTypes[Genes[Gene]['scaffold']][position] = locationType\n",
    "                nearestGeneDict[Genes[Gene]['scaffold']][position] = Gene\n",
    "\n",
    "\n",
    "# Count up locations in promoters, exons, etc\n",
    "locationsByType = {}\n",
    "locationTypeTotals = {}\n",
    "insertionTypeTotals = {}\n",
    "locationTypeClasses = ['intron', 'exon','intergenic']\n",
    "for locationType in locationTypeClasses:\n",
    "    locationTypeTotals[locationType] = 0\n",
    "    insertionTypeTotals[locationType] = 0\n",
    "    locationsByType[locationType] = {}\n",
    "    for scaffold in scaffoldOrder:\n",
    "        locationsByType[locationType][scaffold] = []\n",
    "        for location in range(0,scaffoldLengths[scaffold]):\n",
    "            if locationTypes[scaffold][location] == locationType:\n",
    "                locationsByType[locationType][scaffold].append(location)\n",
    "                locationTypeTotals[locationType]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying insertion locations\n"
     ]
    }
   ],
   "source": [
    "# Annotate poolfile\n",
    "\n",
    "# Count up insertions in promoters, exons, etc.\n",
    "codingFractions = []\n",
    "nearestGeneIDs = []\n",
    "insertionTypesOrdered = []\n",
    "statusUpdate =  \"Classifying insertion locations\"\n",
    "print(statusUpdate)\n",
    "\n",
    "for index in poolFrame.index:\n",
    "    scaffold = poolFrame.at[index,'scaffold']\n",
    "    position = int(poolFrame.at[index,'pos'])-1\n",
    "    insertionType = locationTypes[scaffold][position]\n",
    "    insertionTypeTotals[insertionType] += 1\n",
    "    insertionTypesOrdered.append(insertionType)\n",
    "\n",
    "    nearestGene = nearestGeneDict[scaffold][position]\n",
    "    \n",
    "    if nearestGene == 'intergenic':\n",
    "        nearestGeneIDs.append('intergenic')\n",
    "    else:\n",
    "        nearestGeneIDs.append(Genes[nearestGene]['Parent'])\n",
    "        \n",
    "    if insertionType in ['intron','exon']:\n",
    "        flattened_exons = [item for sublist in Genes[nearestGene]['exon'] for item in sublist]\n",
    "        codingStart = min(flattened_exons)\n",
    "        codingStop = max(flattened_exons)\n",
    "        codingFractions.append(int((float(position - codingStart) / (codingStop - codingStart)) * 100))\n",
    "\n",
    "    else:\n",
    "        codingFractions.append(\"NA\")    \n",
    "\n",
    "\n",
    "poolFrame['InsertionType'] = insertionTypesOrdered\n",
    "poolFrame['NearestGene'] = nearestGeneIDs\n",
    "poolFrame['CodingFraction'] = codingFractions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute GC content around insertion sites\n"
     ]
    }
   ],
   "source": [
    "# compute LocalGCpercent and add column\n",
    "\n",
    "\n",
    "# Check GC content around insertion sites\n",
    "\n",
    "print('compute GC content around insertion sites')\n",
    "scaffoldArr = poolFrame['scaffold'].values\n",
    "posArr = poolFrame['pos'].values\n",
    "flankingWindow = 50\n",
    "GCpcts = []\n",
    "scaffGC = []\n",
    "for idx, scaffold in enumerate(scaffoldArr):\n",
    "    pos = int(posArr[idx])\n",
    "    limits = [max(0,pos-flankingWindow),min(pos+flankingWindow,scaffoldLengths[scaffold])]\n",
    "    localSeq = str(scaffoldSequences[scaffold].seq[limits[0]:limits[1]])\n",
    "    Ccount = localSeq.count('C')\n",
    "    Gcount = localSeq.count('G')\n",
    "    GCpcts.append(100*(Gcount + Ccount)/len(localSeq))\n",
    "poolFrame['LocalGCpercent'] = GCpcts\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    548129\n",
       "Name: barcode, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poolFrame['barcode'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote poolfile with gene information to piggyBAC_all20_poolfile_aug12_2020.txt_carly_annotated_for_BarSeq_final.txt\n"
     ]
    }
   ],
   "source": [
    "# add rest of columns needed ID\tAlternateID\tAnnotation\n",
    "gene_to_name_carly = pd.read_csv('annotation_files/gene_to_name_carly.txt',header=0,sep='\\t',low_memory=False)\n",
    "SGD_annotation = pd.read_csv('annotation_files/SGD_annotation_sc_sp.txt',header=0,sep='\\t',low_memory=False)\n",
    "\n",
    "merge1 = pd.merge(poolFrame, gene_to_name_carly, left_on = 'NearestGene', right_on = 'geneID', how='left')\n",
    "merge2 = pd.merge(merge1, SGD_annotation, left_on = 'name', right_on = 'sc_sp_name', how='left')\n",
    "\n",
    "merge2.rename(columns={'geneID': 'ID', 'name': 'AlternateID', 'annotation': 'Annotation'},inplace=True)\n",
    "\n",
    "merge2.drop(columns=['name_1', 'sc_sp_name'],inplace=True)\n",
    "\n",
    "# fix the offending line\n",
    "# bigline = merge2[merge2['barcode'] == 'TGTAATTTTCGCATCAACCA']['All genomic mappings']\n",
    "\n",
    "merge2.at[432601,'All genomic mappings'] = 'none'\n",
    "\n",
    "merge2.to_csv(poolFileName+\"_carly_annotated_for_BarSeq_final.txt\",sep=\"\\t\",index=False)\n",
    "\n",
    "\n",
    "statusUpdate =  \"Wrote poolfile with gene information to \"+ poolFileName+'_carly_annotated_for_BarSeq_final.txt'\n",
    "print(statusUpdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
